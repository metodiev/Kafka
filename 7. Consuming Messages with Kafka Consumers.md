##  Consuming Messages with Kafka Consumers

### 1. What is a Consumer?
A Kafka **Consumer** is a client application that **reads messages** from Kafka topics. Consumers pull data from brokers at their own pace.

---

### 2. Consumer Groups
- Consumers belong to a **consumer group** identified by a `group.id`.
- Kafka distributes partitions of topics among consumers in the same group for **load balancing**.
- Each partition is consumed by only one consumer in the group.
- Multiple consumer groups can consume the same topic independently.

---

### 3. Basic Consumer Workflow
- Connect to Kafka brokers.
- Subscribe to one or more topics.
- Poll for new messages.
- Process messages.
- Commit offsets to track progress.

---

### 4. Key Consumer Configurations

| Config               | Description                                | Example             |
|----------------------|--------------------------------------------|---------------------|
| `bootstrap.servers`   | Kafka broker addresses                     | `localhost:9092`    |
| `group.id`           | Consumer group ID                          | `my-group`          |
| `key.deserializer`   | Deserializer class for the key             | `org.apache.kafka.common.serialization.StringDeserializer` |
| `value.deserializer` | Deserializer class for the value           | `org.apache.kafka.common.serialization.StringDeserializer` |
| `auto.offset.reset`  | What to do when no initial offset is found | `earliest` or `latest` |
| `enable.auto.commit` | Enable automatic offset commits             | `true` or `false`    |

---

### 5. Example: Simple Java Consumer Code
```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my-group");
        props.put("key.deserializer", StringDeserializer.class.getName());
        props.put("value.deserializer", StringDeserializer.class.getName());
        props.put("auto.offset.reset", "earliest");
        props.put("enable.auto.commit", "true");

        Consumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("my-topic"));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Consumed record topic=%s partition=%d offset=%d key=%s value=%s%n",
                            record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
            }
        } finally {
            consumer.close();
        }
    }
}
```