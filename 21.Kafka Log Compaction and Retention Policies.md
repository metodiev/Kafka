##  Kafka Log Compaction and Retention Policies

### 1. What is Log Compaction?
Log compaction ensures Kafka retains at least the latest value for each key within a topic, providing a snapshot-like view of data.


### 2. Retention Policies
- **Time-based retention (`retention.ms`)**: Deletes messages older than the specified time.
- **Size-based retention (`retention.bytes`)**: Deletes oldest segments when log size exceeds limit.
- **Log compaction (`cleanup.policy=compact`)**: Retains latest record per key indefinitely.


### 3. Use Cases for Log Compaction
- Maintaining changelog streams for stateful stream processing.
- Keeping latest configuration or metadata.
- Event sourcing with snapshots.


### 4. Configuring Log Compaction
Example in `server.properties` or topic-level config:
```properties
cleanup.policy=compact
min.cleanable.dirty.ratio=0.5
segment.ms=604800000   # 7 days segment roll

```

### 5. Important Considerations
Log compaction works best with keys that uniquely identify records.
Compaction is asynchronous; old data may still exist temporarily.
Combine time-based and size-based retention for balanced storage.