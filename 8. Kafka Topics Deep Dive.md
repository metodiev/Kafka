## Kafka Topics Deep Dive

### 1. What is a Topic?
A Kafka **Topic** is a named stream of records. It acts like a logical channel where data is published by producers and consumed by consumers.


### 2. Partitioning
- Topics are split into **partitions**.
- Each partition is an ordered, immutable sequence of records.
- Partitions allow Kafka to scale horizontally by parallelizing reads and writes.
- Each record within a partition has a unique **offset**.



### 3. Replication
- Each partition has a **replication factor** for fault tolerance.
- One broker is the **leader** for a partition; others are **followers**.
- Followers replicate data from the leader to stay in sync.
- Kafka ensures only the leader serves read/write requests for its partition.


### 4. Retention Policies
- Kafka retains messages based on:
  - **Time** (retention.ms) – e.g., 7 days.
  - **Size** (retention.bytes) – maximum size per partition.
- When limits are reached, old data is deleted or compacted.
- Retention can be **log compaction** or **deletion**.


### 5. Log Compaction
- Log compaction ensures at least the last known value for each key is retained.
- Useful for changelog or state storage topics.
- Configuration: cleanup.policy=compact


### 6. Topic Creation
- Topics can be created manually via CLI or automatically (if enabled).
- When creating, you specify partitions and replication factor.


### 7. Topic Configurations Summary

| Config               | Description                             | Default / Example       |
|----------------------|---------------------------------------|------------------------|
| partitions         | Number of partitions                   | 1                    |
| replication.factor | Number of replicas per partition      | 3                    |
| retention.ms       | Time to keep messages                  | 604800000 (7 days)   |
| cleanup.policy     | Retention policy: delete or compact| delete              |
| segment.bytes      | Max size of log segment                | 1073741824 (1 GB)    |



### 8. Best Practices
- Choose partition count based on expected throughput and consumer parallelism.
- Set replication factor ≥ 3 for production for reliability.
- Use log compaction for topics holding the latest state.
- Monitor topic sizes and retention policies regularly.



### 9. Summary
Kafka topics are fundamental units of storage and data organization.  
Understanding partitions, replication, and retention is key to designing scalable Kafka solutions.
